{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attribute\n",
    "\n",
    "**Direct Reference** PINN Repository from Jay Roxis\n",
    "\n",
    "**Original Work**: *Maziar Raissi, Paris Perdikaris, and George Em Karniadakis*\n",
    "\n",
    "**Additional Dervative work**: Ben Moseley, PINNs: an introductory crash course\n",
    "\n",
    "**Github Repo** : https://github.com/jayroxis/PINNs/tree/master\n",
    "\n",
    "**Link:** https://github.com/jayroxis/PINNs/blob/master/Burgers%20Equation/Burgers%20Identification%20(PyTorch).ipynb\n",
    "\n",
    "@article{raissi2017physicsI,\n",
    "  title={Physics Informed Deep Learning (Part I): Data-driven Solutions of Nonlinear Partial Differential Equations},\n",
    "  author={Raissi, Maziar and Perdikaris, Paris and Karniadakis, George Em},\n",
    "  journal={arXiv preprint arXiv:1711.10561},\n",
    "  year={2017}\n",
    "}\n",
    "\n",
    "@article{raissi2017physicsII,\n",
    "  title={Physics Informed Deep Learning (Part II): Data-driven Discovery of Nonlinear Partial Differential Equations},\n",
    "  author={Raissi, Maziar and Perdikaris, Paris and Karniadakis, George Em},\n",
    "  journal={arXiv preprint arXiv:1711.10566},\n",
    "  year={2017}\n",
    "}\n",
    "\n",
    "Data gathered from the Ontario Ministry of Health and Statistics Canada"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries and Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '../Utilities/')\n",
    "\n",
    "import torch\n",
    "from collections import OrderedDict\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.io\n",
    "import warnings\n",
    "import time\n",
    "from scipy.integrate import odeint\n",
    "import pandas as pd\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Check device availability**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CUDA support \n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class for generating dense deep network architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the deep neural network\n",
    "class DNN(torch.nn.Module):\n",
    "    def __init__(self, layers):\n",
    "        super(DNN, self).__init__()\n",
    "        \n",
    "        # parameters\n",
    "        self.depth = len(layers) - 1\n",
    "        \n",
    "        # set up layer order dict\n",
    "        self.activation = torch.nn.Tanh\n",
    "        \n",
    "        layer_list = list()\n",
    "        for i in range(self.depth - 1): \n",
    "            layer_list.append(\n",
    "                ('layer_%d' % i, torch.nn.Linear(layers[i], layers[i+1]))\n",
    "            )\n",
    "            layer_list.append(('activation_%d' % i, self.activation()))\n",
    "            \n",
    "        layer_list.append(\n",
    "            ('layer_%d' % (self.depth - 1), torch.nn.Linear(layers[-2], layers[-1]))\n",
    "        )\n",
    "        layerDict = OrderedDict(layer_list)\n",
    "        \n",
    "        # deploy layers\n",
    "        self.layers = torch.nn.Sequential(layerDict)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.layers(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Physics Informed Neural Network Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the physics-guided neural network\n",
    "class PhysicsInformedNN():\n",
    "    def __init__(self, t_data, t_physics, X, N, layers):\n",
    "        \n",
    "        # data\n",
    "        self.X = torch.tensor(X, requires_grad=True).float().to(device)\n",
    "        self.S, self.I, self.R, self.D = self.X\n",
    "        self.t_data = torch.tensor(t_data, requires_grad=True).float().to(device)\n",
    "        self.t_physics = torch.tensor(t_physics, requires_grad=True).float().to(device)\n",
    "        self.N = N\n",
    "        \n",
    "        # initialize unkown model parameter(s)\n",
    "        self.beta_param = torch.nn.Parameter(torch.rand(1, requires_grad=True).to(device))\n",
    "        self.gamma_param = torch.nn.Parameter(torch.rand(1, requires_grad=True).to(device))\n",
    "        self.mu_param = torch.nn.Parameter(torch.rand(1, requires_grad=True).to(device))\n",
    "        \n",
    "\n",
    "        # deep neural network\n",
    "        self.dnn = DNN(layers).to(device)\n",
    "        self.dnn.register_parameter('gamma', self.gamma_param)\n",
    "        self.dnn.register_parameter('beta', self.beta_param)\n",
    "        self.dnn.register_parameter('mu', self.mu_param)\n",
    "\n",
    "        # Define coefficients to tune loss component weights\n",
    "        self.res_comp_scale = 1.0\n",
    "        self.res_pop_scale = 0.0001\n",
    "        self.data_scale = 1.0\n",
    "        self.IC_scale = 0.0#1.0\n",
    "\n",
    "        #Compartment ICs\n",
    "        #optional compartment IC\n",
    "        self.S_init = torch.tensor(self.S[0], requires_grad=True).float().to(device)\n",
    "        self.I_init = torch.tensor(self.I[0], requires_grad=True).float().to(device)\n",
    "        self.R_init = torch.tensor(self.R[0], requires_grad=True).float().to(device)\n",
    "        self.D_init = torch.tensor(self.D[0], requires_grad=True).float().to(device)\n",
    "        self.t_init = torch.tensor([[0.]], requires_grad=True).float().to(device)\n",
    "\n",
    "        # store separate losses for visualization (per epoch)\n",
    "        self.losses = []\n",
    "        self.datalosses = []\n",
    "        self.residlosses = []\n",
    "        self.Nlosses = []\n",
    "        self.IClosses = []\n",
    "        self.betas = [] #track progress of 'beta'\n",
    "        self.gammas = [] #track progress of 'gamma'\n",
    "        self.mus = [] #track progress of 'mu'\n",
    "\n",
    "         # optimizers: using the same settings\n",
    "        l_r = 5e-4\n",
    "        self.optimizer_Adam = torch.optim.Adam(self.dnn.parameters(), lr = l_r)\n",
    "        self.iter = 0\n",
    "\n",
    "    #force parameters to be in a range\n",
    "    @property\n",
    "    def beta(self):\n",
    "        return torch.tanh(abs(self.beta_param))\n",
    "\n",
    "    @property\n",
    "    def gamma(self):\n",
    "        return torch.tanh(abs(self.gamma_param))\n",
    "\n",
    "    @property\n",
    "    def mu(self):\n",
    "        return torch.tanh(abs(self.mu_param))\n",
    "    \n",
    "    def net_x(self, t):  \n",
    "        out = self.dnn(t)\n",
    "        S = torch.reshape(out[:,0], (len(t), 1))\n",
    "        I = torch.reshape(out[:,1], (len(t), 1))\n",
    "        D = torch.reshape(out[:,2], (len(t), 1))\n",
    "        R = torch.reshape(out[:,3], (len(t), 1))\n",
    "        return S, I, D, R\n",
    "    \n",
    "    def net_f(self, t):\n",
    "        \"\"\" The pytorch autograd version of calculating residual \"\"\"       \n",
    "        snet, inet, dnet, rnet = self.net_x(t)\n",
    "\n",
    "        snet_t = torch.autograd.grad(\n",
    "            snet, t, \n",
    "            grad_outputs=torch.ones_like(snet),\n",
    "            create_graph=True,\n",
    "        )[0]\n",
    "        inet_t = torch.autograd.grad(\n",
    "            inet, t, \n",
    "            grad_outputs=torch.ones_like(inet),\n",
    "            create_graph=True,\n",
    "        )[0]\n",
    "        dnet_t = torch.autograd.grad(\n",
    "            dnet, t, \n",
    "            grad_outputs=torch.ones_like(dnet),\n",
    "            create_graph=True,\n",
    "        )[0]\n",
    "        rnet_t = torch.autograd.grad(\n",
    "            rnet, t, \n",
    "            grad_outputs=torch.ones_like(rnet),\n",
    "            create_graph=True,\n",
    "        )[0]\n",
    "\n",
    "        s_res = snet_t + (self.beta / self.N)*snet*inet\n",
    "        i_res = inet_t -  (self.beta / self.N)*snet*inet + self.gamma*inet + self.mu*inet\n",
    "        d_res = dnet_t - self.mu*inet\n",
    "        r_res = rnet_t - self.gamma*inet\n",
    "        N_res = self.N - snet - inet - dnet - rnet\n",
    "        return s_res, i_res, d_res, r_res, N_res\n",
    "    \n",
    "    def train(self, nIter):\n",
    "        self.dnn.train()\n",
    "        for epoch in range(nIter+1):\n",
    "            s_pred, i_pred, d_pred, r_pred = self.net_x(self.t_data)\n",
    "            s_init, i_init, d_init, r_init = self.net_x(self.t_init) #Initial conditions from network\n",
    "            s_res_pred, i_res_pred, d_res_pred, r_res_pred, N_res_pred = self.net_f(self.t_physics)\n",
    "\n",
    "            loss_data = (torch.mean(torch.square(self.S - s_pred)) +\n",
    "                        torch.mean(torch.square(self.I - i_pred)) + \n",
    "                        torch.mean(torch.square(self.D - d_pred)) +\n",
    "                        torch.mean(torch.square(self.R - r_pred)))\n",
    "            loss_resid = (torch.mean(torch.square(s_res_pred)) +\n",
    "                        torch.mean(torch.square(i_res_pred)) + \n",
    "                        torch.mean(torch.square(d_res_pred)) +\n",
    "                        torch.mean(torch.square(r_res_pred)))\n",
    "            loss_N =  torch.mean(torch.square(N_res_pred))\n",
    "            loss_init = (torch.mean(torch.square(r_init - self.R_init)) +\n",
    "                        torch.mean(torch.square(i_init - self.I_init)) +\n",
    "                        torch.mean(torch.square(d_init - self.D_init)) +          \n",
    "                        torch.mean(torch.square(s_init - self.S_init)))\n",
    "            loss = self.res_comp_scale*loss_resid + self.data_scale*loss_data + self.res_pop_scale*loss_N + self.IC_scale*loss_init\n",
    "\n",
    "            # Backward and optimize\n",
    "            self.optimizer_Adam.zero_grad()\n",
    "            loss.backward()\n",
    "            self.optimizer_Adam.step()\n",
    "            #self.adam_schedule.step()\n",
    "            self.betas.append(self.beta.item())\n",
    "            self.gammas.append(self.gamma.item())\n",
    "            self.mus.append(self.mu.item())\n",
    "\n",
    "            if epoch % 100 == 0:\n",
    "                self.losses.append(loss.item())\n",
    "                self.residlosses.append(self.res_comp_scale*loss_resid.item())\n",
    "                self.datalosses.append(self.data_scale*loss_data.item())\n",
    "                self.IClosses.append(self.IC_scale*loss_init.item())\n",
    "                self.Nlosses.append(self.res_pop_scale*loss_N.item())\n",
    "                print(\n",
    "                    'It: %d, Loss: %.5f, beta: %.5f, gamma: %.3f, mu: %.3f ' % \n",
    "                    (\n",
    "                        epoch, \n",
    "                        loss.item(),\n",
    "                        self.beta.item(),\n",
    "                        self.gamma.item(),\n",
    "                        self.mu.item()\n",
    "                    )\n",
    "                )\n",
    "    \n",
    "    def predict(self, t):\n",
    "        self.dnn.eval()\n",
    "        #net_x is 'predicted' based off of what is given\n",
    "        s, i, d, r = self.net_x(t)\n",
    "        s = s.detach().cpu().numpy()\n",
    "        i = i.detach().cpu().numpy()\n",
    "        d = d.detach().cpu().numpy()\n",
    "        r = r.detach().cpu().numpy()\n",
    "\n",
    "        return s, i, d, r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data/SIRD_organized_data.csv')\n",
    "datanp = data.to_numpy()\n",
    "# Total Ontario Population via Statcan (2020 estimate)\n",
    "N = 14761811\n",
    "#212 data points\n",
    "S = datanp[:,1:2].astype('float64')\n",
    "I = datanp[:,2:3].astype('float64')\n",
    "R = datanp[:,3:4].astype('float64')\n",
    "D = datanp[:,4:5].astype('float64')\n",
    "# Normalize relative to static population estimate\n",
    "Snorm = S/N\n",
    "Inorm = I/N\n",
    "Rnorm = R/N\n",
    "Dnorm = D/N\n",
    "#create a vector for time\n",
    "t = np.linspace(0,211,212)\n",
    "t = np.reshape(t,(212,1))\n",
    "Ynorm = Snorm, Inorm, Rnorm, Dnorm\n",
    "Y = S, I, R, D\n",
    "duration = 211\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Synthetic Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12,12))\n",
    "ax = fig.add_subplot(111, facecolor='#dddddd', axisbelow=True)\n",
    "ax.set_facecolor('xkcd:white')\n",
    "\n",
    "#ax.plot(t, Snorm, 'violet', alpha=0.5, lw=2, label='Susceptible', linestyle='dashed')\n",
    "ax.plot(t, Inorm, 'darkgreen', alpha=0.5, lw=2, label='Infected', linestyle='dashed')\n",
    "ax.plot(t, Dnorm, 'blue', alpha=0.5, lw=2, label='Dead', linestyle='dashed')\n",
    "ax.plot(t, Rnorm, 'red', alpha=0.5, lw=2, label='Recovered', linestyle='dashed')\n",
    "\n",
    "ax.set_xlabel('Time /days')\n",
    "ax.set_ylabel('Fraction of Population')\n",
    "ax.yaxis.set_tick_params(length=0)\n",
    "ax.xaxis.set_tick_params(length=0)\n",
    "ax.grid()\n",
    "legend = ax.legend()\n",
    "legend.get_frame().set_alpha(0.5)\n",
    "for spine in ('top', 'right', 'bottom', 'left'):\n",
    "    ax.spines[spine].set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# network configuration\n",
    "layers = [1, 32, 32, 32, 32, 32, 32, 32, 32, 4]\n",
    "# line up physics mesh to align with baseline\n",
    "timesteps_phys = 1000\n",
    "t_phys = np.linspace(0,duration,timesteps_phys)\n",
    "t_phys = np.transpose(t_phys)\n",
    "t_phys = np.reshape(t_phys, (len(t_phys),1))\n",
    "model = PhysicsInformedNN(t, t_phys, Ynorm, 1, layers)\n",
    "\n",
    "#check number of params\n",
    "total_params = sum(p.numel() for p in model.dnn.parameters())\n",
    "print(total_params)\n",
    "\n",
    "model.train(60000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot true result comparison to network output\n",
    "t_inter = np.linspace(0,211,1000)\n",
    "t_inter = np.transpose(t_inter)\n",
    "t_inter = np.reshape(t_inter, (len(t_inter),1))\n",
    "ttensor = torch.tensor(t_inter).float().to(device)\n",
    "[snet, inet, dnet, rnet] = model.predict(ttensor)\n",
    "plt.plot(t_inter, snet, color = 'red', label = 'susceptible network', linestyle = 'dashed')\n",
    "plt.plot(t, Snorm, color = 'red', label = 'susceptible')\n",
    "'''\n",
    "plt.plot(t_inter, inet, color = 'blue', label = 'infected network', linestyle = 'dashed')\n",
    "plt.plot(t, Inorm, color = 'blue', label = 'infected')\n",
    "plt.plot(t_inter, dnet, color = 'black', label = 'dead network', linestyle = 'dashed')\n",
    "plt.plot(t, Dnorm, color = 'black', label = 'dead')\n",
    "plt.plot(t_inter, rnet, color = 'green', label = 'recovered network', linestyle = 'dashed')\n",
    "plt.plot(t, Rnorm, color = 'green', label = 'recovered')\n",
    "'''\n",
    "plt.legend()\n",
    "plt.title('Network recreation of training dataset')\n",
    "plt.xlabel('Time [days]')\n",
    "plt.ylabel('Fraction of population')\n",
    "plt.show()\n",
    "\n",
    "#Plot Noisy Loss (ADAM)\n",
    "plt.plot(model.losses[0:],color = 'black', label = \"Total\")\n",
    "plt.plot(model.residlosses[0:],color = 'green', label = \"Compartment residuals\")\n",
    "plt.plot(model.datalosses[0:],color = 'orange', label = \"Data\")\n",
    "plt.plot(model.Nlosses[0:], color = 'blue', label = \"Population residual\")\n",
    "plt.plot(model.IClosses[0:],color = 'purple', label = \"IC\")\n",
    "plt.legend()\n",
    "plt.yscale(\"log\")\n",
    "plt.title(\"Loss trends under ADAM optimization\")\n",
    "plt.xlabel('Epochs (in hundreds)')\n",
    "plt.ylabel('Loss [base 10 log]')\n",
    "plt.show()\n",
    "# Print final loss components\n",
    "print('Adam final losses')\n",
    "print('Loss:  %.4e, Residuals loss: %.4e, Data loss: %.4e, Pop Conservation loss: %.4e, IC Loss: %.4e' % \n",
    "        (\n",
    "            model.losses[-1],\n",
    "            model.residlosses[-1],\n",
    "            model.datalosses[-1],\n",
    "            model.Nlosses[-1],\n",
    "            model.IClosses[-1]\n",
    "        )\n",
    "    )\n",
    "\n",
    "\n",
    "print('Estimated beta value')\n",
    "print(model.beta.item())\n",
    "\n",
    "print('Estimated gamma value')\n",
    "print(model.gamma.item())\n",
    "\n",
    "print('Estimated mu value')\n",
    "print(model.mu.item())\n",
    "\n",
    "# plot the learned SIRD parameters vs true SIRD parameters\n",
    "plt.plot(model.betas[0:], color = 'teal', label =\"beta\")\n",
    "plt.plot(model.gammas[0:], color = 'red', label=\"gamma\")\n",
    "plt.plot(model.mus[0:], color = 'green', label=\"mu\")\n",
    "plt.legend()\n",
    "plt.title('Change in Parameter estimation')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Parameter value')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare parameter estimates data via constructing the SIRD model\n",
    "S compartment is plotted separately from I, R, D compartments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compartmentaldiff(y, t, beta, gamma, mu):\n",
    "    S, I, R, D = y\n",
    "    Sdot = - (beta) * S * I\n",
    "    Idot = (beta) * S * I - gamma * I - mu * I\n",
    "    Rdot = gamma * I\n",
    "    Ddot = mu * I\n",
    "\n",
    "    return Sdot, Idot, Rdot, Ddot\n",
    "\n",
    "beta = model.beta.item()\n",
    "gamma = model.gamma.item()\n",
    "mu = model.mu.item()\n",
    "\n",
    "Snorm0 = Snorm[0,0]\n",
    "Inorm0 = Inorm[0,0]\n",
    "Rnorm0 = Rnorm[0,0]\n",
    "Dnorm0 = Dnorm[0,0]\n",
    "tee = np.reshape(t_phys, (1000))\n",
    "y0 = Snorm0, Inorm0, Rnorm0, Dnorm0\n",
    "ret = odeint(compartmentaldiff, y0, tee, args=(beta, gamma, mu))\n",
    "Smod, Imod, Rmod, Dmod = ret.T\n",
    "\n",
    "# Plot data against parameter estimation\n",
    "plt.plot(tee, Smod, color = 'red', label = 'susceptible model', linestyle = 'dashed')\n",
    "plt.plot(t, Snorm, color = 'red', label = 'susceptible')\n",
    "'''\n",
    "plt.plot(tee, Imod, color = 'blue', label = 'infected model', linestyle = 'dashed')\n",
    "plt.plot(t, Inorm, color = 'blue', label = 'infected')\n",
    "plt.plot(tee, Dmod, color = 'black', label = 'dead model', linestyle = 'dashed')\n",
    "plt.plot(t, Dnorm, color = 'black', label = 'dead')\n",
    "plt.plot(tee, Rmod, color = 'green', label = 'recovered model', linestyle = 'dashed')\n",
    "plt.plot(t, Rnorm, color = 'green', label = 'recovered')\n",
    "'''\n",
    "plt.legend()\n",
    "plt.title('Data vs SIRD model')\n",
    "plt.xlabel('Time [days]')\n",
    "plt.ylabel('Fraction of population')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
