{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attribute\n",
    "\n",
    "**Direct Reference**: pinn_ode_tutorial-master github repository\n",
    "\n",
    "**Original Work**: *Renato Nascimento, Kajetan Fricke, Felipe Viana*\n",
    "\n",
    "**Reference Github repo** https://github.com/PML-UCF/pinn_ode_tutorial.git\n",
    "\n",
    "Data gathered from the Ontario Ministry of Health and Statistics Canada"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries and Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as matplotlib\n",
    "\n",
    "from torch.nn.parameter import Parameter\n",
    "from torch import (\n",
    "    linalg,\n",
    "    nn,\n",
    "    Tensor,\n",
    "    stack,\n",
    "    cat,\n",
    "    transpose, \n",
    "    optim,\n",
    "    zeros,\n",
    "    diag,\n",
    "    reshape,\n",
    "    rand,\n",
    "    tanh,\n",
    "    mean,\n",
    "    square\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hybrid RNN Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construct / Deploy Hybrid RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyRNN(nn.Module):\n",
    "    def __init__(self, cell, **kwargs):\n",
    "        super(MyRNN, self).__init__()\n",
    "        self.cell = cell\n",
    "\n",
    "    def forward(self, inputs, initial_state):\n",
    "        # Step into proceeding timestep\n",
    "        bs, seq_sz, _ = inputs.shape\n",
    "        state = []\n",
    "        state.append(initial_state)\n",
    "        for t in range(1, seq_sz): \n",
    "            input = inputs[:, t-1, :]\n",
    "            state_t = self.cell.forward(input, state[t-1])\n",
    "            state.append(state[t-1]+state_t)\n",
    "\n",
    "        return stack((state),dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construct Runge-Kutta Cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RungeKuttaIntegratorCell(nn.Module):\n",
    "    def __init__(self, beta, gamma, mu, u, dt, **kwargs):\n",
    "        super(RungeKuttaIntegratorCell, self).__init__(**kwargs)\n",
    "\n",
    "        self.beta_param = Parameter(beta)\n",
    "        self.gamma_param = Parameter(gamma)\n",
    "        self.mu_param = Parameter(mu)\n",
    "        \n",
    "        # Runge-Kutta iterative vectors\n",
    "        self.state_size   =  4\n",
    "        self.A  = Tensor([0., 0.5, 0.5, 1.0])\n",
    "        self.B  = Tensor([[1/6, 2/6, 2/6, 1/6]])\n",
    "        self.dt = dt\n",
    "        \n",
    "     #force parameters to be in a range\n",
    "    @property\n",
    "    def beta(self):\n",
    "        return tanh(abs(self.beta_param))\n",
    "\n",
    "    @property\n",
    "    def gamma(self):\n",
    "        return tanh(abs(self.gamma_param))\n",
    "\n",
    "    @property\n",
    "    def mu(self):\n",
    "        return tanh(abs(self.mu_param))\n",
    "\n",
    "    def forward(self, inputs, states):\n",
    "        y = states\n",
    "        #Perform Runge-Kutta computation\n",
    "        ydoti = self._fun(beta, gamma, mu, y)\n",
    "        yi = y + self.A[0]*ydoti*self.dt\n",
    "        fn = self._fun(beta, gamma, mu, yi)\n",
    "        #Perfom Runge-Kutta Computation\n",
    "        for j in range(1,4):\n",
    "            yn = y + self.A[j] * ydoti * self.dt\n",
    "            fn = cat([fn, self._fun(beta, gamma, mu, yn)], dim=0)\n",
    "\n",
    "        y    = linalg.matmul(self.B, fn) * self.dt\n",
    "        return y\n",
    "\n",
    "    def _fun(self, beta, gamma, mu, y):\n",
    "        Sdot = -self.beta*y[0,0]*y[0,1]\n",
    "        Idot = self.beta*y[0,0]*y[0,1] - self.gamma*y[0,1] - self.mu*y[0,1]\n",
    "        Rdot = self.gamma*y[0,1]\n",
    "        Ddot = self.mu*y[0,1]\n",
    "        ydot = cat(([Sdot,Idot,Rdot,Ddot]), dim = -1)\n",
    "        ydot = reshape(ydot,(1,4))\n",
    "\n",
    "        return ydot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pinn_training_loop(n_epochs, optimizer, model, loss_fn, train, label, initial_state):\n",
    "    mae = nn.L1Loss()\n",
    "    losses = []\n",
    "    betas = []\n",
    "    gammas = []\n",
    "    mus = []\n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "        #Forward pass\n",
    "        output_train = model(train, initial_state)\n",
    "        loss_train = (mean(square(output_train[0,:,0] - label[0,:,0])) +\n",
    "                        mean(square(output_train[0,:,1] - label[0,:,1])) + \n",
    "                        mean(square(output_train[0,:,2] - label[0,:,2])) +\n",
    "                        mean(square(output_train[0,:,3] - label[0,:,3])))\n",
    "        mae_train = mae(output_train, label)\n",
    "        losses.append(loss_train.item())\n",
    "        betas.append(beta.item())\n",
    "        gammas.append(gamma.item())\n",
    "        mus.append(mu.item())\n",
    "        #Backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss_train.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        print(f\"Epoch {epoch}, Training loss {loss_train.item():.4e}, mae {mae_train.item():.4e}\")\n",
    "        \n",
    "    return losses, betas, gammas, mus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Execute Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize params randomly\n",
    "beta = rand(1)\n",
    "gamma = rand(1)\n",
    "mu = rand(1)\n",
    "print(tanh(abs(beta)))\n",
    "print(tanh(abs(gamma)))\n",
    "print(tanh(abs(mu)))\n",
    "\n",
    "data = pd.read_csv('data/SIRD_organized_data.csv')\n",
    "datanp = data.to_numpy()\n",
    "\n",
    "# Total Ontario Population via Statcan (2020 estimate)\n",
    "N = 14761811\n",
    "#212 data points\n",
    "S = datanp[:,1:2].astype('float64')\n",
    "I = datanp[:,2:3].astype('float64')\n",
    "R = datanp[:,3:4].astype('float64')\n",
    "D = datanp[:,4:5].astype('float64')\n",
    "# Normalize relative to static population estimate\n",
    "Snorm = S/N\n",
    "Inorm = I/N\n",
    "Rnorm = R/N\n",
    "Dnorm = D/N\n",
    "#create a vector for time\n",
    "t = np.linspace(0,211,212)\n",
    "t = np.reshape(t,(212,1))\n",
    "duration = 211\n",
    "\n",
    "# data\n",
    "dt = (t[1,0] - t[0,0])\n",
    "t = Tensor(t)\n",
    "Stense = Tensor(Snorm)\n",
    "Itense = Tensor(Inorm)\n",
    "Rtense = Tensor(Rnorm)\n",
    "Dtense = Tensor(Dnorm)\n",
    "ytrain = cat(([Stense,Itense,Rtense,Dtense]),dim=1)\n",
    "utrain = zeros(ytrain.size())\n",
    "\n",
    "#resize tensors\n",
    "t = reshape(t,(len(t),1))\n",
    "ufull = reshape(utrain, (1, len(t), 4))\n",
    "yfull = reshape(ytrain, (1, len(t), 4))\n",
    "\n",
    "# Initial state of the system \n",
    "initial_state = zeros(1,4)\n",
    "initial_state[0,0] = Stense[0]\n",
    "initial_state[0,1] = Itense[1]\n",
    "initial_state[0,2] = Rtense[2]\n",
    "initial_state[0,3] = Dtense[3]\n",
    "\n",
    "rkCell = RungeKuttaIntegratorCell(beta = beta, gamma = gamma, mu = mu, u = ufull, dt=dt)\n",
    "model = MyRNN(cell=rkCell)\n",
    "    \n",
    "#prediction results before training\n",
    "yPred_before = model(ufull, initial_state)\n",
    "yPred_before = yPred_before.detach().numpy()[0,:,:]\n",
    "\n",
    "#check number of params\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(total_params)\n",
    "\n",
    "#PINN training\n",
    "losses, betas, gammas, mus = pinn_training_loop(\n",
    "        n_epochs = 1000,\n",
    "        optimizer = optim.Adam(model.parameters(), lr=5e-3),\n",
    "        model = model,\n",
    "        loss_fn = nn.MSELoss(),\n",
    "        train = ufull,\n",
    "        label = yfull,\n",
    "        initial_state=initial_state\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# constrained params\n",
    "beta_con = np.tanh(betas)\n",
    "gamma_con = np.tanh(gammas)\n",
    "mu_con = np.tanh(mus)\n",
    "beta_con = list(map(abs, beta_con))\n",
    "gamma_con = list(map(abs, gamma_con))\n",
    "mu_con = list(map(abs, mu_con))\n",
    "print(beta_con[-1])\n",
    "print(gamma_con[-1])\n",
    "print(mu_con[-1])\n",
    "#prediction results after training\n",
    "yPred = model(ufull, initial_state) [0, :, :]\n",
    "yPred = yPred.detach().numpy()\n",
    "\n",
    "#plt.plot(t, yPred[:,0], color = 'red', label = 'susceptible network', linestyle = 'dashed')\n",
    "#plt.scatter(t, Snorm, color = 'red', label = 'susceptible')\n",
    "\n",
    "plt.plot(t, yPred[:,1], color = 'blue', label = 'infected network', linestyle = 'dashed')\n",
    "plt.scatter(t, Inorm, color = 'blue', label = 'infected')\n",
    "plt.plot(t, yPred[:,3], color = 'black', label = 'dead network', linestyle = 'dashed')\n",
    "plt.scatter(t, Dnorm, color = 'black', label = 'dead')\n",
    "plt.plot(t, yPred[:,2], color = 'green', label = 'recovered network', linestyle = 'dashed')\n",
    "plt.scatter(t, Rnorm, color = 'green', label = 'recovered')\n",
    "\n",
    "\n",
    "plt.legend()\n",
    "#plt.title('Network recreation of training dataset')\n",
    "plt.xlabel('Time [days]')\n",
    "plt.ylabel('Fraction of population')\n",
    "plt.show()\n",
    "\n",
    "# Loss\n",
    "plt.plot(losses,color = 'black')\n",
    "plt.yscale(\"log\")\n",
    "#plt.title(\"Loss trend under Adam optimization\")\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss [base 10 log]')\n",
    "plt.show()\n",
    "\n",
    "# plot the learned SIRD parameters vs true SIRD parameters\n",
    "plt.plot(beta_con[0:], color = 'teal', label =\"beta\")\n",
    "plt.plot(gamma_con[0:], color = 'red', label=\"gamma\")\n",
    "plt.plot(mu_con[0:], color = 'green', label=\"mu\")\n",
    "plt.legend()\n",
    "#plt.title('Change in Parameter estimation')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Parameter value')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
