{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attribute\n",
    "\n",
    "**Direct Reference**: pinn_ode_tutorial-master github repositor\n",
    "\n",
    "**Original Work**: *Renato Nascimento, Kajetan Fricke, Felipe Viana*\n",
    "**Reference Github repo** https://github.com/PML-UCF/pinn_ode_tutorial.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries and Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as matplotlib\n",
    "\n",
    "from torch.nn.parameter import Parameter\n",
    "from torch import (\n",
    "    linalg,\n",
    "    nn,\n",
    "    Tensor,\n",
    "    stack,\n",
    "    cat,\n",
    "    transpose, \n",
    "    optim,\n",
    "    zeros,\n",
    "    diag,\n",
    "    reshape,\n",
    "    rand,\n",
    "    tanh,\n",
    "    mean,\n",
    "    square\n",
    "    )\n",
    "\n",
    "#For Data Generation\n",
    "from scipy import signal\n",
    "from scipy import linalg as linalg2\n",
    "from scipy.integrate import odeint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Underlying Model and Training Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compartmentaldiff(y, t, beta, gamma, mu):\n",
    "    S, I, D, R = y\n",
    "    Sdot = - (beta / N) * S * I\n",
    "    Idot = (beta / N) * S * I - gamma * I - mu * I\n",
    "    Rdot = gamma * I\n",
    "    Ddot = mu * I\n",
    "\n",
    "    return Sdot, Idot, Ddot, Rdot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial conditions\n",
    "Ntrue = 59e6 #true population size\n",
    "N = 1.0 #population size squished into 1 for ease of training\n",
    "S0 = (Ntrue - 1)/Ntrue\n",
    "I0 = N - S0\n",
    "R0 = 0\n",
    "D0 = 0\n",
    "y0 = S0, I0, D0, R0\n",
    "\n",
    "# A grid of time points (in days)\n",
    "timesteps = 100\n",
    "duration = 500\n",
    "t = np.linspace(0, duration, timesteps)\n",
    "\n",
    "# compartmental model parameters\n",
    "beta_syn = 0.191\n",
    "gamma_syn = 0.05\n",
    "mu_syn = 0.0294\n",
    "\n",
    "# Integrate the SIR equations over the time grid, t.\n",
    "ret = odeint(compartmentaldiff, y0, t, args=(beta_syn, gamma_syn, mu_syn))\n",
    "S, I, D, R = ret.T\n",
    "S = np.reshape(S, (len(t), 1))\n",
    "I = np.reshape(I, (len(t), 1))\n",
    "D = np.reshape(D, (len(t), 1))\n",
    "R = np.reshape(R, (len(t), 1))\n",
    "\n",
    "\n",
    "#reshape time vector\n",
    "t_data = np.transpose(t)\n",
    "t_data = np.reshape(t_data, (len(t),1))\n",
    "\n",
    "# keep clean data\n",
    "Sc = S\n",
    "Ic = I\n",
    "Dc = D\n",
    "Rc = R\n",
    "\n",
    "#relative noise\n",
    "noise = 0.05\n",
    "S = (1 + noise * np.random.normal(0,1, S.shape)) * S\n",
    "I = (1 + noise * np.random.normal(0,1, I.shape)) * I\n",
    "D = (1 + noise * np.random.normal(0,1, D.shape)) * D\n",
    "R = (1 + noise * np.random.normal(0,1, R.shape)) * R"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hybrid RNN Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construct / Deploy Hybrid RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyRNN(nn.Module):\n",
    "    def __init__(self, cell, **kwargs):\n",
    "        super(MyRNN, self).__init__()\n",
    "        self.cell = cell\n",
    "\n",
    "    def forward(self, inputs, initial_state):\n",
    "        # Step into proceeding timestep\n",
    "        bs, seq_sz, _ = inputs.shape\n",
    "        state = []\n",
    "        state.append(initial_state)\n",
    "        for t in range(1, seq_sz): \n",
    "            input = inputs[:, t-1, :]\n",
    "            state_t = self.cell.forward(input, state[t-1])\n",
    "            state.append(state[t-1]+state_t)\n",
    "\n",
    "        return stack((state),dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construct Runge-Kutta Cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RungeKuttaIntegratorCell(nn.Module):\n",
    "    def __init__(self, beta, gamma, mu, u, dt, **kwargs):\n",
    "        super(RungeKuttaIntegratorCell, self).__init__(**kwargs)\n",
    "\n",
    "        self.beta_param = Parameter(beta)\n",
    "        self.gamma_param = Parameter(gamma)\n",
    "        self.mu_param = Parameter(mu)\n",
    "        \n",
    "        # Runge-Kutta iterative vectors\n",
    "        self.state_size   =  4\n",
    "        self.A  = Tensor([0., 0.5, 0.5, 1.0])\n",
    "        self.B  = Tensor([[1/6, 2/6, 2/6, 1/6]])\n",
    "        self.dt = dt\n",
    "        \n",
    "     #force parameters to be in a range\n",
    "    @property\n",
    "    def beta(self):\n",
    "        return tanh(abs(self.beta_param))\n",
    "\n",
    "    @property\n",
    "    def gamma(self):\n",
    "        return tanh(abs(self.gamma_param))\n",
    "\n",
    "    @property\n",
    "    def mu(self):\n",
    "        return tanh(abs(self.mu_param))\n",
    "\n",
    "    def forward(self, inputs, states):\n",
    "        y = states\n",
    "        #Perform Runge-Kutta computation\n",
    "        ydoti = self._fun(beta, gamma, mu, y)\n",
    "        yi = y + self.A[0]*ydoti*self.dt\n",
    "        fn = self._fun(beta, gamma, mu, yi)\n",
    "        #Perfom Runge-Kutta Computation\n",
    "        for j in range(1,4):\n",
    "            yn = y + self.A[j] * ydoti * self.dt\n",
    "            fn = cat([fn, self._fun(beta, gamma, mu, yn)], dim=0)\n",
    "\n",
    "        y    = linalg.matmul(self.B, fn) * self.dt\n",
    "        return y\n",
    "\n",
    "    def _fun(self, beta, gamma, mu, y):\n",
    "        Sdot = -self.beta*y[0,0]*y[0,1]\n",
    "        Idot = self.beta*y[0,0]*y[0,1] - self.gamma*y[0,1] - self.mu*y[0,1]\n",
    "        Rdot = self.gamma*y[0,1]\n",
    "        Ddot = self.mu*y[0,1]\n",
    "        ydot = cat(([Sdot,Idot,Rdot,Ddot]), dim = -1)\n",
    "        ydot = reshape(ydot,(1,4))\n",
    "\n",
    "        return ydot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pinn_training_loop(n_epochs, optimizer, scheduler, model, loss_fn, train, label, initial_state):\n",
    "    mae = nn.L1Loss()\n",
    "    losses = []\n",
    "    betas = []\n",
    "    gammas = []\n",
    "    mus = []\n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "        #Forward pass\n",
    "        output_train = model(train, initial_state)\n",
    "        loss_train = (mean(square(output_train[0,:,0] - label[0,:,0])) +\n",
    "                        mean(square(output_train[0,:,1] - label[0,:,1])) + \n",
    "                        mean(square(output_train[0,:,2] - label[0,:,2])) +\n",
    "                        mean(square(output_train[0,:,3] - label[0,:,3])))\n",
    "        mae_train = mae(output_train, label)\n",
    "        losses.append(loss_train.item())\n",
    "        betas.append(beta.item())\n",
    "        gammas.append(gamma.item())\n",
    "        mus.append(mu.item())\n",
    "        #Backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss_train.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "        print(f\"Epoch {epoch}, Training loss {loss_train.item():.4e}, mae {mae_train.item():.4e}\")\n",
    "        \n",
    "    return losses, betas, gammas, mus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Execute Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize params randomly\n",
    "beta = rand(1)\n",
    "gamma = rand(1)\n",
    "mu = rand(1)\n",
    "print(tanh(abs(beta)))\n",
    "print(tanh(abs(gamma)))\n",
    "print(tanh(abs(mu)))\n",
    "\n",
    "# data\n",
    "dt = (t[1] - t[0])\n",
    "t = Tensor(t)\n",
    "Stense = Tensor(S)\n",
    "Itense = Tensor(I)\n",
    "Rtense = Tensor(R)\n",
    "Dtense = Tensor(D)\n",
    "ytrain = cat(([Stense,Itense,Rtense,Dtense]),dim=1)\n",
    "utrain = zeros(ytrain.size())\n",
    "\n",
    "#resize tensors\n",
    "t = reshape(t,(len(t),1))\n",
    "ufull = reshape(utrain, (1, len(t), 4))\n",
    "yfull = reshape(ytrain, (1, len(t), 4))\n",
    "\n",
    "# Initial state of the system \n",
    "initial_state = zeros(1,4)\n",
    "initial_state[0,0] = y0[0]\n",
    "initial_state[0,1] = y0[1]\n",
    "\n",
    "rkCell = RungeKuttaIntegratorCell(beta = beta, gamma = gamma, mu = mu, u = ufull, dt=dt)\n",
    "model = MyRNN(cell=rkCell)\n",
    "    \n",
    "#prediction results before training\n",
    "yPred_before = model(ufull, initial_state)\n",
    "yPred_before = yPred_before.detach().numpy()[0,:,:]\n",
    "\n",
    "#check number of params\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(total_params)\n",
    "\n",
    "#PINN training\n",
    "losses, betas, gammas, mus = pinn_training_loop(\n",
    "        n_epochs = 500,\n",
    "        optimizer = optim.Adam(model.parameters(), lr=1e-2),\n",
    "        scheduler = optim.lr_scheduler.CyclicLR(optim.Adam(model.parameters(), lr=1e-2), base_lr=1e-2, \\\n",
    "            max_lr=1e3, step_size_up=50, mode=\"exp_range\", gamma=0.85, cycle_momentum=False),\n",
    "        model = model,\n",
    "        loss_fn = nn.MSELoss(),\n",
    "        train = ufull,\n",
    "        label = yfull,\n",
    "        initial_state=initial_state\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# constrained params\n",
    "beta_con = np.tanh(betas)\n",
    "gamma_con = np.tanh(gammas)\n",
    "mu_con = np.tanh(mus)\n",
    "beta_con = list(map(abs, beta_con))\n",
    "gamma_con = list(map(abs, gamma_con))\n",
    "mu_con = list(map(abs, mu_con))\n",
    "print(beta_con[-1])\n",
    "print(gamma_con[-1])\n",
    "print(mu_con[-1])\n",
    "#prediction results after training\n",
    "yPred = model(ufull, initial_state) [0, :, :]\n",
    "yPred = yPred.detach().numpy()\n",
    "\n",
    "plt.plot(t, yPred[:,0], color = 'red', label = 'susceptible network', linestyle = 'dashed')\n",
    "plt.scatter(t, S, color = 'red', label = 'susceptible')\n",
    "plt.plot(t, yPred[:,1], color = 'blue', label = 'infected network', linestyle = 'dashed')\n",
    "plt.scatter(t, I, color = 'blue', label = 'infected')\n",
    "plt.plot(t, yPred[:,3], color = 'black', label = 'dead network', linestyle = 'dashed')\n",
    "plt.scatter(t, D, color = 'black', label = 'dead')\n",
    "plt.plot(t, yPred[:,2], color = 'green', label = 'recovered network', linestyle = 'dashed')\n",
    "plt.scatter(t, R, color = 'green', label = 'recovered')\n",
    "'''\n",
    "#True values\n",
    "plt.plot(t, Sc, color = 'red')\n",
    "plt.plot(t, Ic, color = 'blue')\n",
    "plt.plot(t, Dc, color = 'black')\n",
    "plt.plot(t, Rc, color = 'green')\n",
    "'''\n",
    "plt.legend()\n",
    "#plt.title('Network recreation of training dataset')\n",
    "plt.xlabel('Time [days]')\n",
    "plt.ylabel('Fraction of population')\n",
    "plt.show()\n",
    "\n",
    "# Loss\n",
    "plt.plot(losses,color = 'black')\n",
    "plt.yscale(\"log\")\n",
    "#plt.title(\"Loss trend under Adam optimization\")\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss [base 10 log]')\n",
    "plt.show()\n",
    "\n",
    "# plot the learned SIRD parameters vs true SIRD parameters\n",
    "plt.plot(beta_con[0:], color = 'teal', label =\"beta\")\n",
    "plt.plot(gamma_con[0:], color = 'red', label=\"gamma\")\n",
    "plt.plot(mu_con[0:], color = 'green', label=\"mu\")\n",
    "plt.axhline(y = 0.191, color = 'teal', linestyle = 'dashed', label =\"betagoal\")\n",
    "plt.axhline(y = 0.05, color = 'red', linestyle = 'dashed', label =\"gammagoal\")\n",
    "plt.axhline(y = 0.0294, color = 'green', linestyle = 'dashed', label =\"mugoal\")\n",
    "plt.legend()\n",
    "#plt.title('Change in Parameter estimation')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Parameter value')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
